{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPvKwCAqMIv78HuyFAyzGBX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Hotel Bookings Cancellations - Understanding Data Leakage\n","\n","In the evaluation process, both during model validation and testing phases, I compared the performance between an original model and another I intentionally modified to include data leakage through the variable  `early_cancellation_or_noshow`. This variable provides advance insight into cancellations, acting as an early indicator of the booking outcome.\n","\n","## Model Performance Without Data Leakage\n","\n","For the original model, accuracy and recall metrics during the validation phase were 0.8088 and 0.7134, respectively. During the testing phase, accuracy was 0.8146 with a recall of 0.7607. These metrics reflect the model's performance based on features without foreknowledge of the outcomes.\n","\n","## Impact of Data Leakage\n","\n","However, with the introduction of data leakage, both accuracy and recall metrics soared to 0.9997 in the validation phase, and to 0.9994 for accuracy and 0.9992 for recall in the testing phase. This significant inflation in perceived model performance demonstrates how data leakage can falsely enhance a machine learning model's effectiveness by providing it with information that would not realistically be available at the time of making predictions.\n","\n","The almost perfect accuracy and recall achieved with data leakage suggest substantial overfitting, as the model has \"learned\" the outcomes directly from the training data, rather than generalizing from learned features.\n","\n","## The Critical Importance of Avoiding Data Leakage\n","\n","This experiment underscores the critical importance of identifying and preventing data leakage in predictive modeling practice. The intentional inclusion of data leakage in this case study showed how it could affect performance evaluations, resulting in metrics that do not truly represent the model's predictive capability.\n","\n","These findings highlight the necessity for careful data preparation and feature selection practices to ensure models are robust, generalizable, and reliable in real applications, thus avoiding the false precision that data leakage can induce.\n"],"metadata":{"id":"jNT3SCCjYl1s"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Set up the variable for your file path\n","file_path =  'data/hotel_bookings_training.csv' #or the Google Drive path"],"metadata":{"id":"GX7l6ZEH04c-"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"35fkuMQGz5c7"},"outputs":[],"source":["import pandas as pd\n","\n","hotel_bookings = pd.read_csv(file_path)\n","\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","source":["hotel_bookings.info()"],"metadata":{"id":"pDzagr0t00hP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Remove personal information of customers\n","hotel_bookings = hotel_bookings.drop(['name', 'email', 'phone-number', 'credit_card'], axis=1)"],"metadata":{"id":"nFCDZ3ZA09lq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["hotel_bookings.sample(10)"],"metadata":{"id":"p1kf57y81J2v"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##EDA"],"metadata":{"id":"SSpDZ6KP1f70"}},{"cell_type":"code","source":["!pip install pandas_profiling"],"metadata":{"id":"aAit7Uoj2fCk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from ydata_profiling import ProfileReport # Previously pandas_profiling # Create a report on our data in an HTML file"],"metadata":{"id":"gmuP13ks2ook"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["profile = ProfileReport(hotel_bookings, title=\"Pandas Profiling Report\")"],"metadata":{"id":"20AtsxXi2z8M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install matplotlib\n","!pip install --upgrade Pillow\n","import matplotlib.pyplot as plt\n","profile.to_file(\"data/bookings_profile.html\")"],"metadata":{"id":"0g39d6yo3OPX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!ls"],"metadata":{"id":"egjl3MxM3exI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import files\n","files.download('data/bookings_profile.html')"],"metadata":{"id":"zuM576pB3nYL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Intentional Data Leakage\n","\n"],"metadata":{"id":"5jp8HFnu8L39"}},{"cell_type":"markdown","source":["Data leakage occurs when information from outside the training dataset is used to create the model. This can happen in two main ways:\n","\n","Not hiding certain information (e.g., accidentally including personal information that directly correlates with the target variable).\n","Using test/validation data for training.\n","This can lead to the model learning patterns it shouldn't know, resulting in misleadingly high performance when evaluated with the same data. However, this performance may significantly drop on new or unseen data.\n","\n","# Introducing Data Leakage for Testing Purposes\n","To demonstrate the effects of data leakage I deliberately retain the 'reservation_status' variable instead of excluding it and I use the 'reservation_status_date' variable to create another variable that will create data leakege because it directly reflects the is_canceled outcome. This approach allows us to examine the significant impact data leakage can have on the model's perceived performance.\n","\n","Note: In real-world scenarios, it's crucial to avoid data leakage to ensure the model's predictions are genuine and applicable.\n","\n","This approach helps illustrate the importance of careful feature selection to prevent unrealistic model performance estimations.\n"],"metadata":{"id":"ked9MF_l4n2I"}},{"cell_type":"markdown","source":["## Retention of the `reservation_status` variable\n","\n","The `reservation_status` variable indicates the status of the reservation, which is actually a reflection of `is_canceled`. If it is included among the input variables, I am effectively leaking information to the model. This will yield excellent results, but in reality, it won't be of any use in real-life scenarios."],"metadata":{"id":"hVRayvhJHWAq"}},{"cell_type":"code","source":["#I deliberately retain the 'reservation_status's variable\n","#hotel_bookings = hotel_bookings.drop(['reservation_status', 'reservation_status_date'], axis=1)"],"metadata":{"id":"b7FOD2p26PEJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Creation of the `early_cancellation_or_noshow` variable based on the `duration_to_arrival` variable, obtained through `arrival_date` and `reservation_status_date`"],"metadata":{"id":"hP5ZAzXvHhMT"}},{"cell_type":"code","source":["from datetime import datetime\n","\n","# The year and day of the month are converted to string format to enable concatenation with the month for the 'arrival_date'.\n","hotel_bookings['arrival_date'] = pd.to_datetime(hotel_bookings['arrival_date_year'].astype(str) + '-' +\n","                                                hotel_bookings['arrival_date_month'] + '-' +\n","                                                hotel_bookings['arrival_date_day_of_month'].astype(str))\n","\n","# Ensuring that 'reservation_status_date' is formatted as datetime, similar to 'arrival_date'.\n","hotel_bookings['reservation_status_date'] = pd.to_datetime(hotel_bookings['reservation_status_date'])\n","\n","# The duration (in days) between the reservation status date and the arrival date is calculated.\n","hotel_bookings['duration_to_arrival'] = (hotel_bookings['reservation_status_date'] - hotel_bookings['arrival_date']).dt.days\n"],"metadata":{"id":"d8uJwrQ2FzsJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data Verification\n","\n","### Checking Data Types\n","I verified the data types for date columns to ensure they were in the proper format for analysis.\n","\n","\n"],"metadata":{"id":"oaFIUjdqJPPx"}},{"cell_type":"code","source":["print(hotel_bookings[['arrival_date', 'reservation_status_date']].dtypes)"],"metadata":{"id":"11b1gIKtJRUI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Comparing Original and Transformed Columns\n","I displayed original and transformed columns side by side to assess the effectiveness of my data transformations."],"metadata":{"id":"hnGutWclJW9P"}},{"cell_type":"code","source":["hotel_bookings[['arrival_date_year', 'arrival_date_month', 'arrival_date_day_of_month', 'arrival_date', 'reservation_status_date', 'duration_to_arrival']].head()"],"metadata":{"id":"K34DngJCJZjX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Analyzing Null Values\n","I inspected the distribution of the 'duration_to_arrival' column, including its null values, to identify any patterns or irregularities."],"metadata":{"id":"F-uHuLrEJdSa"}},{"cell_type":"code","source":["print(hotel_bookings['duration_to_arrival'].describe())"],"metadata":{"id":"6ziNr45UJgG3"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Evaluating Negative Values\n","I identified and examined rows with negative durations. These instances are significant as they indicate cancellations that occurred before the scheduled arrival date."],"metadata":{"id":"ne2nUicuJkUh"}},{"cell_type":"code","source":["negative_duration_rows = hotel_bookings[hotel_bookings['duration_to_arrival'] < 0]\n","columns_of_interest = negative_duration_rows[['arrival_date', 'reservation_status_date', 'duration_to_arrival', 'reservation_status']]\n","print(columns_of_interest.head())"],"metadata":{"id":"N7vQAdQzJoCY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Assessing Positive and Zero Durations\n","I reviewed rows with zero or positive durations. Zero durations represent no-shows, while positive durations signify guests who checked in as planned, making these distinctions crucial for model accuracy."],"metadata":{"id":"FTvTXgMEJsdG"}},{"cell_type":"code","source":["positive_and_zero_duration_rows = hotel_bookings[hotel_bookings['duration_to_arrival'] >= 0]\n","columns_of_interest_2 = positive_and_zero_duration_rows[['arrival_date', 'reservation_status_date', 'duration_to_arrival', 'reservation_status']]\n","print(columns_of_interest_2.sample(50))"],"metadata":{"id":"-cDOdqGCJvKz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Conclusion:\n","My analysis showed that negative durations predominantly represent early cancellations, with durations close to zero being especially concerning as they indicate last-minute cancellations or no-shows. Conversely, positive durations typically indicate guests who checked in as anticipated."],"metadata":{"id":"97oL_Xy2J1Sc"}},{"cell_type":"markdown","source":["###Introducing a New Variable for Early Cancellations and No-shows\n","To enhance the model's predictive capability, I created a variable that captures early cancellations and no-shows. This addition is aimed at providing deeper insights into booking behaviors and improving model performance."],"metadata":{"id":"yHDJLu93J4e1"}},{"cell_type":"markdown","source":["#### Importance of Including `early_cancellation_or_noshow` in Training Data\n","\n","When introducing the `early_cancellation_or_noshow` variable to the analysis, it's vital to incorporate it into the hotel_data dataset. This dataset, created from the original hotel_bookings data by excluding the `is_canceled` variable, forms the foundation for the model training.\n","\n","Incorporating the `early_cancellation_or_noshow` variable is a key step. It introduces critical information related to data leakage into the training process, fulfilling the objective of data leakage for testing and analytical purposes. This method results in metrics that might seem \"too good to be true,\" highlighting not an enhancement but an overfitting of the model. This overfitting, while illustrative of the potential impacts of data leakage, does not constitute an improvement in the model's predictive capacity. Instead, it serves as a caution against the misleading accuracy that can arise from improperly incorporating predictive information into the training data.\n","\n"],"metadata":{"id":"SIy6wpDzMsBO"}},{"cell_type":"code","source":["hotel_bookings['early_cancellation_or_noshow'] = ((hotel_bookings['duration_to_arrival'] <= 0).astype(int))\n","print(hotel_bookings.head())"],"metadata":{"id":"xcMPgjHqJ9H9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(hotel_bookings.columns) #Includes the new variable, 'early_cancellation_or_noshow'"],"metadata":{"id":"yutCEDJVOma2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Extract the target variable\n","I carefully extracted the target variable from the dataset, ensuring that the integrity of the data remained intact for accurate model training."],"metadata":{"id":"GAmjQAXg6Zjr"}},{"cell_type":"code","source":["is_canceled = hotel_bookings['is_canceled'].copy()\n","hotel_data = hotel_bookings.drop(['is_canceled'], axis=1)\n","print(hotel_data.columns) #Does not include the new variable, 'early_cancellation_or_noshow'. The hotel_data will be the train_x data."],"metadata":{"id":"I9rZkNSf6fpf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####Verifying Dataset Columns\n","\n","Inspecting the hotel_data columns reveals the absence of the newly introduced 'early_cancellation_or_noshow' variable. It's crucial to include this variable in hotel_data, which will serve as the basis for the training dataset (train_x). This ensures the model is trained with all pertinent features, including those introduced to illustrate the effects of data leakage."],"metadata":{"id":"qHNMdrGCBqTa"}},{"cell_type":"code","source":["hotel_data['early_cancellation_or_noshow'] = hotel_bookings['early_cancellation_or_noshow']\n","print (hotel_data.head())"],"metadata":{"id":"TVtg2_K5BpAb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Splitting the Data into Training, Testing, and Validation Sets\n","Finally, I divided the data into distinct sets for training, testing, and validation. This step is crucial for evaluating the model's performance and its ability to generalize to new, unseen data."],"metadata":{"id":"YxwRiU6P6l6V"}},{"cell_type":"code","source":["# Obtaining the total number of records in the dataset\n","original_count = len(hotel_bookings)\n","\n","# Defining the proportion of the dataset to allocate for training\n","training_size = 0.60  # 60% of records for training\n","\n","# Calculating the sizes for the test and validation sets, splitting the remaining data equally\n","test_size = (1 - training_size) / 2  # 20% for testing, 20% for validation\n","\n","# Calculating the actual number of records for each set based on their proportions\n","training_count = int(original_count * training_size)  # Number of records for training\n","test_count = int(original_count * test_size)  # Number of records for testing\n","validation_count = original_count - training_count - test_count  # Remaining records for validation\n","\n","# Printing out the sizes for each set to verify the distribution\n","print(f\"Training count: {training_count}, Test count: {test_count}, Validation count: {validation_count}, Total: {original_count}\")\n"],"metadata":{"id":"qlU-Oiq_7Js9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","\n","# Splitting the data into training data for 'hotel_data' and the target variable 'is_canceled'.\n","# The dataset is split into training and 'rest' (which includes both test and validation subsets).\n","train_x, rest_x, train_y, rest_y = train_test_split(hotel_data, is_canceled, train_size=training_count)\n","# Here, 'hotel_data' and the target variable 'is_canceled' are being split.\n","# 'train_size' is set to 'training_count' (60% of records as defined above).\n","\n","# Further split the 'rest' data into test and validation sets, each comprising 20% of the total data.\n","test_x, validate_x, test_y, validate_y = train_test_split(rest_x, rest_y, train_size=test_count)\n","# This operation splits the remaining data into test and validation subsets, based on 'test_count'.\n","\n","# Printing the lengths of the training, test, and validation datasets to verify the splits.\n","print(len(train_x), len(test_x), len(validate_x))\n"],"metadata":{"id":"4CujQXNT7ik8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#One-hot encoding"],"metadata":{"id":"pnhfWcXH-aKE"}},{"cell_type":"markdown","source":["One-hot encoding is a technique for converting categorical variables (strings) into a numerical representation. In this case, it applies to the column indicating the hotel type associated with each booking.\n","\n","While Pandas provides a convenient method called get_dummies for quick analysis, it's not reproducible in a production or more formal analysis setting. Instead, it's recommended to use the OneHotEncoder from the scikit-learn library for a more robust and reproducible approach."],"metadata":{"id":"5U5CPoyr-bRa"}},{"cell_type":"markdown","source":["## Variables to Encode - One-hot Encoding"],"metadata":{"id":"ghMAJIpQAOcT"}},{"cell_type":"code","source":["from sklearn.preprocessing import OneHotEncoder"],"metadata":{"id":"ec2OQhX3BeF8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["one_hot_encoder = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")"],"metadata":{"id":"Rs1m7VBrBgWq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["one_hot_encoder.fit(train_x[['hotel']])\n","one_hot_encoder.transform(train_x[['hotel']])"],"metadata":{"id":"NeNopVM8BkpK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["When constructing a One-Hot Encoder, it's advisable to generate a sparse matrix and to ignore unknown variables/values. It's crucial to remember that the .fit method should always be applied to the training data (train_x), while the .transform method should be applied to both the testing (test_x) and validation data (validate_x).\n","\n","For ordinal variables, consider using a Label Encoder instead.\n","\n","In cases of high cardinality - where a categorical variable contains a large number of unique values - it's important to maintain information while reducing the number of categorical variables. Techniques such as embeddings or grouping can be employed to manage variables with high levels of unique values without resorting to one-hot encoding. For instance, a variable representing countries can exhibit high cardinality; in such scenarios, rather than applying one-hot encoding, more advanced techniques like embeddings or grouping countries into categorical variables (like continents) could be used to reduce cardinality effectively.\n","\n","In the context of this project, NLTK (Natural Language Toolkit) is not utilized as there are no extensive text variables to process.\n","\n","However, if your dataset includes variables with substantial text content (such as customer comments), tools and techniques for Natural Language Processing (NLP) in Python, like NLTK, can be highly effective for processing and extracting meaningful information from text data."],"metadata":{"id":"D6HiU3XECP4X"}},{"cell_type":"markdown","source":["#Binarizer"],"metadata":{"id":"4ttQjFwoCtn8"}},{"cell_type":"markdown","source":["## Variables to Binarize\n","\n"," - total_of_special_requests, required_car_parking_spaces, booking_changes, previous_bookings_not_canceled, previous_cancellations"],"metadata":{"id":"gG8aVwBxC54n"}},{"cell_type":"markdown","source":["In this scenario, the chosen approach was to binarize these variables to determine whether a client made a specific request or took a particular action, translating it into a binary format represented as a 0 or 1 value. These variables will be incorporated into the feature engineering pipeline within the binarizer column transformer."],"metadata":{"id":"58FBH1m6Ft9y"}},{"cell_type":"code","source":["from sklearn.preprocessing import Binarizer"],"metadata":{"id":"YRWb14xbDIY8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["binarizer = Binarizer()"],"metadata":{"id":"iuCzwsBEDKhj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x_copy = train_x.copy()\n","\n","binarizer.fit(_[['total_of_special_requests']])\n","train_x_copy['has_made_special_requests'] = binarizer.transform(train_x[['total_of_special_requests']])\n","\n","train_x_copy[['total_of_special_requests', 'has_made_special_requests']].sample(10)"],"metadata":{"id":"JySH3pSfDN9L"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Instead of being a high-cardinality categorical variable, it is now a binary variable with two values, 1 and 0, yes and no."],"metadata":{"id":"_swVl97kDXN_"}},{"cell_type":"markdown","source":[" total_of_special_requests is not ordinal; it cannot be quantified. (Customers who have made 0, 1, 2, 3, 4, 5 special requests.)\n","\n","The requests are different from each other, and the relationship between them varies.\n","Perhaps one request was very specific and another was for two bottles of water.\n","\n","Binarizer: to determine if the customer made any requests or not. (True/False)\n","\n","(see the HTML report, Pandas Profiling Report)\n","\n","booking_changes: the number of changes requested by the customer. Perhaps we are not interested in how many changes the customer made, but whether they made any changes or not.\n","\n","previous_cancellations, previous_bookings_not_canceled: To identify someone who has made cancellations and someone who has not, regardless of the number.\n","\n","It's not to reduce the model's complexity.\n","Discarding the number of cancellations because it's not as informative.\n","Most clients did not cancel.\n","It improves the model, making it more general.\n","\n","Reducing the model's complexity also reduces the execution time during training and testing, which is more economical.\n","\n","Binarizer Documentation:\n","Specify the threshold. To determine if few or many requests were made, if more than 3, mark the requests as positive; if less, 0. binarizer = Binarizer (threshold=3)\n","\n","One might choose not to binarize a variable in another case; the total requests could be treated as ordinal in another scenario.\n"],"metadata":{"id":"ojkSLskCDwwn"}},{"cell_type":"markdown","source":["#Scaler"],"metadata":{"id":"4w7jmTbvFhl9"}},{"cell_type":"markdown","source":["## Variable to scale\n","\n"," - adr"],"metadata":{"id":"D73NWdcbFlrh"}},{"cell_type":"markdown","source":["In the scikit-learn documentation, there are general recommendations on using scalers, which can be particularly useful for variables representing how much a hotel earns when it's occupied. This can include rooms that generate profit and others that result in losses, creating a wide range of values from -6 to 5000.\n","\n","There are various scalers such as StandardScaler, MinMaxScaler (for normally distributed data), and AbsoluteScaler. For cases with skewed data and extraordinary outliers, which deviate significantly from the expected range, a different approach is recommended.\n","\n","The RobustScaler, as detailed in scikit-learn's documentation, is specifically designed to handle outliers effectively. This scaler adjusts the data in a way that is less influenced by the presence of outliers, making it a suitable choice for variables with a wide range of values and potential outlier data points."],"metadata":{"id":"q8GgHZG_GSVk"}},{"cell_type":"code","source":["from sklearn.preprocessing import RobustScaler"],"metadata":{"id":"1uKTtAWwGhfe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scaler = RobustScaler()"],"metadata":{"id":"2p4gP2kvGjh7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_x_copy = train_x.copy()\n","scaler.fit(_[['adr']])\n","train_x_copy['adr_scaled'] = scaler.transform(train_x[['adr']])\n","\n","train_x_copy[['adr', 'adr_scaled']].sample(10)"],"metadata":{"id":"FZ5ZC6j1Gmxe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The result is a smaller range that our machine learning model can handle."],"metadata":{"id":"I9IdTMKzHIZG"}},{"cell_type":"markdown","source":["Standardization is a specific form of data scaling. Generally, in the context of data preprocessing for machine learning, scaling refers to modifying the values of features (variables) to fit them onto a common scale. There are several ways to do this, with normalization and standardization being two of the most common.\n","\n","**Standardization**\n","Standardization involves rescaling data so they have a mean (μ) of 0 and a standard deviation (σ) of 1. The formula for standardizing a feature is:\n","\n","\n","### **z = (x - μ) / σ**\n","\n","where \\(x\\)  is the original value, (μ) is the mean of the feature, and\n","(σ) is the standard deviation of the feature. Standardization does not bound values to a specific range.\n","\n","**Normalization**\n","On the other hand, normalization (often referred to as min-max scaling) rescales the data to a specific range, typically 0 to 1. The formula for normalization is:\n","\n","### **xnorm = (x - x_min)/(x_max - x_min)**\n","\n","where x_min and x_max are the minimum and maximum values of the feature, respectively.\n","\n","Comparison and Usage\n","\n","Standardization vs. Normalization: The choice between standardization and normalization depends on the specific model and the context of the problem.\n","\n","Some machine learning models, like those that assume the data is **normally distributed**, may benefit more from standardization.\n","\n","Others, especially those **sensitive to the magnitude of features but that do not assume a specific distribution**, like distance-based models, may benefit more from normalization.\n","\n","Invariance of Standardization: Standardization is invariant to the scale of measurement, meaning it changes the data to a scale that is relative to the mean and standard deviation of the data, making it useful for comparisons and for models that are sensitive to variance in the data but not necessarily to the absolute magnitude.\n","\n","In summary, both standardization and normalization are important data preprocessing techniques that scale features but do so in ways that may be more suitable for different types of models and analysis problems.\n","\n","Bimodal and Multimodal Distributions\n","\n","Scaling does not affect whether a distribution is bimodal or multimodal.\n","It depends. You should delve deeper into scaling techniques to use the scaler that best fits the data.\n","**It is always recommended to scale the data regardless of its distribution.**"],"metadata":{"id":"ldFToAx1HcNa"}},{"cell_type":"markdown","source":["#No Transformation"],"metadata":{"id":"mPrJqHhjLUiM"}},{"cell_type":"markdown","source":["###Variables to Maintain in Their Original Form:\n","\n"," - stays_in_weekend_nights, stays_in_week_nights\n","\n","The approach to these variables is contingent upon the predictive model selected for implementation.\n","\n","It is essential to evaluate the nature and assumptions of the chosen model to determine whether these variables require any form of transformation or can be incorporated directly in their original state."],"metadata":{"id":"0lheaYI7LlId"}},{"cell_type":"markdown","source":["#Transformation Pipeline"],"metadata":{"id":"6noN7G4ML4D2"}},{"cell_type":"markdown","source":["The transformation pipeline groups together various transformations to be applied to the data, streamlining the preprocessing phase. This approach enables the efficient execution of multiple operations in unison, ensuring consistency across the dataset. The pipeline is particularly useful for applying specific transformations, such as one-hot encoding, to several variables simultaneously."],"metadata":{"id":"Z-xb_MO_MOwO"}},{"cell_type":"markdown","source":["Applying One-Hot Encoding\n","One-hot encoding is a crucial step in preparing categorical variables for machine learning models. This process converts categorical data into a format that can be provided to ML algorithms to improve prediction accuracy. In our pipeline, we use a ColumnTransformer to apply one-hot encoding to specified columns. The ColumnTransformer targets columns for transformation, ensuring that the encoded output is aligned with the corresponding feature in our dataset. The variables targeted for one-hot encoding in this case include: hotel, meal, distribution_channel, reserved_room_type, assigned_room_type, and customer_type. This methodical application of one-hot encoding across multiple variables enhances the model's ability to understand and utilize categorical data effectively."],"metadata":{"id":"-fJ1w_p6MULo"}},{"cell_type":"code","source":["from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import FeatureUnion, Pipeline"],"metadata":{"id":"4TcLrlTFMYNZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["one_hot_encoding = ColumnTransformer([\n","    (\n","        'one_hot_encode',\n","        OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\"),\n","        [\n","            \"hotel\",\n","            \"meal\",\n","            \"distribution_channel\",\n","            \"reserved_room_type\",\n","            \"assigned_room_type\",\n","            \"customer_type\"\n","        ]\n","    )\n","])"],"metadata":{"id":"qfcVJaRcMb50"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["binarizer = ColumnTransformer([\n","    (\n","        'binarizer',\n","        Binarizer(),\n","        [\n","            \"total_of_special_requests\",\n","            \"required_car_parking_spaces\",\n","            \"booking_changes\",\n","            \"previous_bookings_not_canceled\",\n","            \"previous_cancellations\",\n","        ]\n","    )\n","])\n","#This one-hot encoder breaks down categorical variables into a binary format (0 and 1), effectively eliminating any hierarchy or order within the categories.\n","one_hot_binarized = Pipeline([ #both\n","    (\"binarizer\", binarizer),\n","    (\"one_hot_encoder\", OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")),\n","])"],"metadata":{"id":"09Mjt7RYMfQc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["scaler = ColumnTransformer([\n","    (\"scaler\", RobustScaler(), [\"adr\"])\n","])"],"metadata":{"id":"UPchp4LrMh7P"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###The passthrough approach\n","\n","It allows for certain features to remain unaltered, ensuring that the original data structure is preserved for these specific variables while still benefiting from the one-hot encoding applied to other categorical variables."],"metadata":{"id":"Xl4UcDoaN7cZ"}},{"cell_type":"markdown","source":["### Including Key Variables in the Passthrough Transformer\n","\n","Ensuring 'early_cancellation_or_noshow' is passed through unchanged is crucial. Variables not specified in the ColumnTransformer are ignored by the model, neither influencing training nor predictions. This step guarantees the model accounts for all relevant data, including our intentionally added data leakage variable for analysis."],"metadata":{"id":"Q9TkBjhoN35A"}},{"cell_type":"code","source":["passthrough = ColumnTransformer([\n","    (\n","        \"passthrough\",\n","        \"passthrough\",\n","        [\n","            \"stays_in_week_nights\",\n","            \"stays_in_weekend_nights\",\n","            \"early_cancellation_or_noshow\",  # Add the variable here.\n","        ]\n","    )\n","])"],"metadata":{"id":"l_u6XBb7MmeA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In machine learning workflows, efficiently managing data transformations is crucial for model performance. The process typically involves three key steps:\n","\n","* Preparation of Individual Transformers or Pipelines: For specific groups of columns, individual transformers or pipelines are prepared to handle different data types or perform specific transformations, such as one-hot encoding for categorical variables or scaling for numerical variables.\n","\n","* Integration into a Unified Feature Engineering Scheme: These transformers are then integrated into a global schema using either FeatureUnion or ColumnTransformer. This allows for the parallel application of all necessary transformations, ensuring a comprehensive and efficient feature engineering process.\n","\n","* Global Pipeline Construction: The final step involves encapsulating the entire feature engineering process and the machine learning model into a global pipeline. This global pipeline, which can be considered a 'pipeline of pipelines,' ensures a seamless workflow from data preprocessing to model training and prediction.\n","\n","This structured approach not only facilitates the management of complex data transformations but also prevents common errors such as data leakage, enhancing model development and deployment efficiency"],"metadata":{"id":"1aSeZVU9NpcP"}},{"cell_type":"markdown","source":["## Feature Engineering Pipeline with Feature Union\n","\n","This process consolidates all prior transformations, for which individual pipelines were created, into a comprehensive feature engineering pipeline. Essentially, it acts as a 'pipeline of pipelines,' effectively grouping together various transformation pipelines.\n","\n","The Feature Union object serves as the core component, facilitating the merger of all transformation elements into a unified whole. This streamlined approach ensures that all specified transformations are applied in parallel, optimizing the feature engineering process for the machine learning model."],"metadata":{"id":"xC24cyS4ORY4"}},{"cell_type":"code","source":["# Defining the feature engineering pipeline\n","feature_engineering_pipeline = Pipeline(\n","    [\n","        (  # A tuple with the name 'features' and the FeatureUnion object\n","            \"features\",\n","            FeatureUnion(\n","                [\n","                    (\"categorical\", one_hot_encoding),  # An identifier/any name and the one-hot encoder\n","                    (\"categorical_binarized\", one_hot_binarized),  # Binarized categorical features\n","                    (\"scaled\", scaler),  # Scaled features\n","                    (\"pass\", passthrough),  # Features to pass through without transformation\n","                ]\n","            ),\n","        )\n","    ]\n",")"],"metadata":{"id":"Nor9g1OsOVNl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Applying the pipeline to the training data\n","transformed = feature_engineering_pipeline.fit_transform(train_x)\n","print(f\"Transformed shape: {transformed.shape}\")"],"metadata":{"id":"22lXPd24Otn_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transformed # It's a matrix that our model can handle."],"metadata":{"id":"_fQ7iEgWO6Ry"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model training"],"metadata":{"id":"tSJ20lQsO_8k"}},{"cell_type":"code","source":["# Getting a fresh copy of the pipeline\n","from sklearn.base import clone\n","\n","feature_transformer = clone(feature_engineering_pipeline)  # Obtaining an untrained copy of the pipeline.\n","\n","features_train_x = feature_transformer.fit_transform(train_x)  # Training the pipeline and use it to transform the training dataset.\n","features_validate_x = feature_transformer.transform(validate_x)  # Transforming the validation dataset.\n"],"metadata":{"id":"5JdW6_fSPPfg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The dataset is now converted to numbers so the model can be trained."],"metadata":{"id":"nAmHmLcHPZJw"}},{"cell_type":"code","source":["from sklearn.ensemble import RandomForestClassifier\n","from sklearn.svm import LinearSVC\n","\n","model = RandomForestClassifier(n_estimators=100) # Vary n_estimators to improve recall during validation.\n","\n","model.fit(features_train_x, train_y)\n"],"metadata":{"id":"B_ofOQ0GPi8A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model validation"],"metadata":{"id":"PVP7sJ5WPmax"}},{"cell_type":"markdown","source":["The validation dataset serves as a critical tool for evaluating the model's performance, with a particular focus on the **recall score**. In this process, the model, already trained, is applied to identify the most suitable hyperparameters for optimal performance.\n","\n","During this phase, while the algorithm employs the features from features_train_x to refine the model's internal parameters, the role of a data scientist is to leverage the validation dataset for the fine-tuning of the hyperparameters, enhancing the control over the model's behavior.\n","\n","TRAINING DATA: This dataset is instrumental for the model to learn and adjust its internal parameters.\n","VALIDATION DATA: Conversely, this dataset is utilized by the data scientist to fine-tune the hyperparameters, aiming to optimize the model's performance.\n","The **modification of hyperparameters**, informed by the model's performance on metrics such as **recall and accuracy score**, is pivotal to ensuring the model's effectiveness. This approach underscores the iterative process of model refinement, where both the model's internal learning and the data scientist's strategic adjustments play crucial roles in achieving optimal predictive performance."],"metadata":{"id":"_k0gv3svP30I"}},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score, recall_score\n","\n","pred_y = model.predict(features_validate_x)\n","\n","print(accuracy_score(validate_y, pred_y))\n","print(recall_score(validate_y, pred_y))"],"metadata":{"id":"G2D9b2-QPuZO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Results:\n","\n","0.99970635120396\n","\n","0.9996552120445926"],"metadata":{"id":"R4RIRuI6PxgA"}},{"cell_type":"markdown","source":["Attempting to enhance the model involves:\n","- Adjusting the hyperparameters of the **RandomForestClassifier**, specifically the **n_estimators**, during model training. Evaluate performance on model validation using recall and accuracy score to determine the optimal estimators/hyperparameters based on the best results.\n","- Exploring other models such as **Support Vector Machines, Logistic Regression**, and others could also improve outcomes.\n","\n","These results can be further improved by experimenting with different models or adjusting parameters/hyperparameters."],"metadata":{"id":"nNFFy0dnQToJ"}},{"cell_type":"markdown","source":["# Construction of the Final Pipeline\n","\n","This final pipeline encapsulates the entire data processing and modeling flow, ensuring a streamlined and reproducible approach for prediction."],"metadata":{"id":"YjJ3eRbCQ4kn"}},{"cell_type":"code","source":["final_inference_pipeline = Pipeline([\n","    # Incorporate a fresh copy of the pre-established feature engineering pipeline.\n","    (\"feature_engineering\", clone(feature_engineering_pipeline)),\n","\n","    # Model selection with pre-defined hyperparameters.\n","    (\"model\", RandomForestClassifier(n_estimators=100))\n","])"],"metadata":{"id":"UV_2hyM9Q0en"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Concatenating the training data with the validation data to create a large dataset:"],"metadata":{"id":"eMo6qqYiRMav"}},{"cell_type":"code","source":["final_training_dataset = pd.concat([train_x, validate_x])  # 95352 records in total\n","final_training_response = pd.concat([train_y, validate_y])"],"metadata":{"id":"GSgD_RwBRbiN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Instead of using only the initial training dataset, I concatenate the training and validation datasets to create a larger dataset. This enhanced dataset is then used to train the model that will be deployed into production."],"metadata":{"id":"8RWjjg7dRkqR"}},{"cell_type":"markdown","source":["The dataset comprises the input variables, while the response includes the binary values 1 and 0."],"metadata":{"id":"XEg3yljkRvJA"}},{"cell_type":"markdown","source":["Training the final pipeline which was created above with these data:"],"metadata":{"id":"On-C170-R82t"}},{"cell_type":"code","source":["final_inference_pipeline.fit(final_training_dataset, final_training_response)"],"metadata":{"id":"jiyOpvE5R_rj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Model testing"],"metadata":{"id":"UGJKK316R2bX"}},{"cell_type":"markdown","source":["Seeing how the model performs in the real world:"],"metadata":{"id":"bjiSuTa_SQaH"}},{"cell_type":"code","source":["test_pred_y = final_inference_pipeline.predict(test_x)\n","\n","print(accuracy_score(test_pred_y, test_y))\n","print(recall_score(test_pred_y, test_y))"],"metadata":{"id":"aXqR9gRuSWvC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Results:\n","\n","0.9994127024079201\n","\n","0.9992082343626286\n","\n","These are data that evaluate the model's effectiveness.\n","\n","###Interpreting Results: successful data leakage (not recommended in real-life scenarios)\n","The results, showing accuracy and recall scores of approximately 0.9994 and 0.9992 respectively, align with the anticipation of overfitting due to deliberately induced data leakage. This level of performance, while seemingly exceptional, is indicative of the model having access to information it would not have in a realistic scenario, leading to inflated metrics. This serves as a clear demonstration of how data leakage can artificially enhance a model's performance, underscoring the necessity of vigilance against such pitfalls in model training and validation processes."],"metadata":{"id":"z9O-1Y8vSmc1"}},{"cell_type":"markdown","source":["## Model persistence"],"metadata":{"id":"SZfvwF56TF72"}},{"cell_type":"markdown","source":["\n","An artifact refers to any object or file created as a result of training a machine learning model. In this case, there is only one piece, the model itself. In other scenarios, when not using pipelines, there might be multiple components to deploy to production."],"metadata":{"id":"3_ueuPt-TgvF"}},{"cell_type":"code","source":["from joblib import dump\n","\n","dump(final_inference_pipeline, \"inference_pipeline.joblib\")"],"metadata":{"id":"KfwHufuwTnRS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["\n","# New clients - checking the model performance"],"metadata":{"id":"qNE7bgxkUlna"}},{"cell_type":"code","source":["from joblib import load\n","\n","ultimate_inference_pipeline = load(\"inference_pipeline.joblib\")"],"metadata":{"id":"H2QSHNHxUp4h"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This involves a file with 100 new clients that the hotel wants to get evaluated using the model to determine if they will cancel or not."],"metadata":{"id":"19cwby8wUsnx"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Set up the variable for your file path\n","file_path = '/content/drive/My Drive/My Colabs/enhanced_hotel_cancellation_prediction/data/new_customers.csv'\n","#file_path = 'data/new_customers.csv'\n","\n","new_customers = pd.read_csv(file_path)\n","new_customers.head()\n","\n","new_customers['will_cancel'] = ultimate_inference_pipeline.predict(new_customers)  # adds the column 'will_cancel', indicating if a customer will cancel (1) or not (0).\n","new_customers[['proba_check_in', 'proba_cancel']] = ultimate_inference_pipeline.predict_proba(new_customers)  # 'predict_proba' provides a probability estimate of a customer canceling or not.\n","\n","# Selects the columns and sorts them in descending order by 'proba_cancel'.\n","new_customers[['name', 'phone-number', 'will_cancel', 'proba_cancel']].sort_values(by='proba_cancel', ascending=False).head(20)\n"],"metadata":{"id":"IpC-774iUv9j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Final Overview: The Implications of Data Leakage\n","\n","In this data leakage exploration, I intentionally incorporated the 'early_cancellation_or_noshow' variable to shed light on its profound impact on model performance. This strategic inclusion aimed to demonstrate the effects of data leakage for testing and analytical purposes. By comparing an original model's performance against a version modified to include this variable, I observed a stark difference in outcomes during both model validation and testing phases.\n","\n","Initially, the original model, free from data leakage, displayed modest performance metrics: an accuracy of 0.8146 and a recall of 0.7607 during the testing phase. However, upon introducing the 'early_cancellation_or_noshow' variable, a variable that provides advanced insights into cancellation likelihoods, I witnessed a dramatic increase in performance. Accuracy and recall metrics soared to near-perfection—0.9997 in validation and 0.9994 for accuracy, with a recall of 0.9992 in the testing phase.\n","\n","This experiment highlights the deceptive nature of data leakage, illustrating how it can artificially inflate a model's effectiveness by giving it access to information not realistically available at the time of prediction. The elevated performance metrics, while impressive at first glance, actually signal substantial overfitting. The model, in essence, \"learned\" the outcomes from the training data rather than through generalizing from the features it was intended to analyze.\n","\n","These findings serve as a stark reminder of the critical need for vigilance against data leakage in the model training and validation processes. Ensuring that models are developed with integrity, trained on realistically obtainable information, and free from future insights is essential for maintaining the robustness and reliability of their predictive capabilities in real-world applications.\n"],"metadata":{"id":"KkhFPtwWVYBf"}}]}